; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 6
; RUN: opt -passes=slp-vectorizer -S -slp-revec -mtriple=aarch64-unknown-linux-gnu < %s | FileCheck %s

define <16 x i64> @test() {
; CHECK-LABEL: define <16 x i64> @test() {
; CHECK-NEXT:  [[ENTRY:.*:]]
; CHECK-NEXT:    [[TMP0:%.*]] = call <64 x i64> @llvm.smin.v64i64(<64 x i64> <i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 -1, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0>, <64 x i64> zeroinitializer)
; CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 0, i32 16, i32 32, i32 48>
; CHECK-NEXT:    [[TMP2:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <16 x i64> poison, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 1, i32 17, i32 33, i32 49>
; CHECK-NEXT:    [[TMP5:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <16 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    [[TMP7:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 2, i32 18, i32 34, i32 50>
; CHECK-NEXT:    [[TMP8:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <16 x i64> [[TMP6]], i64 [[TMP8]], i64 2
; CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 3, i32 19, i32 35, i32 51>
; CHECK-NEXT:    [[TMP11:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP10]])
; CHECK-NEXT:    [[TMP12:%.*]] = insertelement <16 x i64> [[TMP9]], i64 [[TMP11]], i64 3
; CHECK-NEXT:    [[TMP13:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 4, i32 20, i32 36, i32 52>
; CHECK-NEXT:    [[TMP14:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP13]])
; CHECK-NEXT:    [[TMP15:%.*]] = insertelement <16 x i64> [[TMP12]], i64 [[TMP14]], i64 4
; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 5, i32 21, i32 37, i32 53>
; CHECK-NEXT:    [[TMP17:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP16]])
; CHECK-NEXT:    [[TMP18:%.*]] = insertelement <16 x i64> [[TMP15]], i64 [[TMP17]], i64 5
; CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 6, i32 22, i32 38, i32 54>
; CHECK-NEXT:    [[TMP20:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP19]])
; CHECK-NEXT:    [[TMP21:%.*]] = insertelement <16 x i64> [[TMP18]], i64 [[TMP20]], i64 6
; CHECK-NEXT:    [[TMP22:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 7, i32 23, i32 39, i32 55>
; CHECK-NEXT:    [[TMP23:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP22]])
; CHECK-NEXT:    [[TMP24:%.*]] = insertelement <16 x i64> [[TMP21]], i64 [[TMP23]], i64 7
; CHECK-NEXT:    [[TMP25:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 8, i32 24, i32 40, i32 56>
; CHECK-NEXT:    [[TMP26:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP25]])
; CHECK-NEXT:    [[TMP27:%.*]] = insertelement <16 x i64> [[TMP24]], i64 [[TMP26]], i64 8
; CHECK-NEXT:    [[TMP28:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 9, i32 25, i32 41, i32 57>
; CHECK-NEXT:    [[TMP29:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = insertelement <16 x i64> [[TMP27]], i64 [[TMP29]], i64 9
; CHECK-NEXT:    [[TMP31:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 10, i32 26, i32 42, i32 58>
; CHECK-NEXT:    [[TMP32:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP31]])
; CHECK-NEXT:    [[TMP33:%.*]] = insertelement <16 x i64> [[TMP30]], i64 [[TMP32]], i64 10
; CHECK-NEXT:    [[TMP34:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 11, i32 27, i32 43, i32 59>
; CHECK-NEXT:    [[TMP35:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP34]])
; CHECK-NEXT:    [[TMP36:%.*]] = insertelement <16 x i64> [[TMP33]], i64 [[TMP35]], i64 11
; CHECK-NEXT:    [[TMP37:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 12, i32 28, i32 44, i32 60>
; CHECK-NEXT:    [[TMP38:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP37]])
; CHECK-NEXT:    [[TMP39:%.*]] = insertelement <16 x i64> [[TMP36]], i64 [[TMP38]], i64 12
; CHECK-NEXT:    [[TMP40:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 13, i32 29, i32 45, i32 61>
; CHECK-NEXT:    [[TMP41:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP40]])
; CHECK-NEXT:    [[TMP42:%.*]] = insertelement <16 x i64> [[TMP39]], i64 [[TMP41]], i64 13
; CHECK-NEXT:    [[TMP43:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 14, i32 30, i32 46, i32 62>
; CHECK-NEXT:    [[TMP44:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP43]])
; CHECK-NEXT:    [[TMP45:%.*]] = insertelement <16 x i64> [[TMP42]], i64 [[TMP44]], i64 14
; CHECK-NEXT:    [[TMP46:%.*]] = shufflevector <64 x i64> [[TMP0]], <64 x i64> poison, <4 x i32> <i32 15, i32 31, i32 47, i32 63>
; CHECK-NEXT:    [[TMP47:%.*]] = call i64 @llvm.vector.reduce.smin.v4i64(<4 x i64> [[TMP46]])
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <16 x i64> [[TMP45]], i64 [[TMP47]], i64 15
; CHECK-NEXT:    ret <16 x i64> [[TMP48]]
;
entry:
  %0 = zext <16 x i8> splat (i8 1) to <16 x i64>
  %1 = sub <16 x i64> zeroinitializer, %0
  %2 = zext <16 x i8> zeroinitializer to <16 x i64>
  %3 = sub <16 x i64> zeroinitializer, %2
  %4 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %1, <16 x i64> %3)
  %5 = zext <16 x i8> zeroinitializer to <16 x i64>
  %6 = sub <16 x i64> zeroinitializer, %5
  %7 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %4, <16 x i64> %6)
  %8 = zext <16 x i8> zeroinitializer to <16 x i64>
  %9 = sub <16 x i64> zeroinitializer, %8
  %10 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %7, <16 x i64> %9)
  %11 = sub <16 x i64> zeroinitializer, zeroinitializer
  %12 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %10, <16 x i64> %11)
  %13 = sub <16 x i64> zeroinitializer, zeroinitializer
  %14 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %12, <16 x i64> %13)
  %15 = sub <16 x i64> zeroinitializer, zeroinitializer
  %16 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %14, <16 x i64> %15)
  %17 = sub <16 x i64> zeroinitializer, zeroinitializer
  %18 = call <16 x i64> @llvm.smin.v16i64(<16 x i64> %16, <16 x i64> %17)
  ret <16 x i64> %18
}

declare <16 x i64> @llvm.smin.v16i64(<16 x i64>, <16 x i64>)

